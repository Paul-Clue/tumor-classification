{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_paths(path):\n",
    "  classes = []\n",
    "  class_paths = []\n",
    "\n",
    "  # Iterate through directories in the training path\n",
    "  for label in os.listdir(path):\n",
    "    label_path = os.path.join(path, label)\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(label_path):\n",
    "      # Iterate through images in the label directory\n",
    "      for image in os.listdir(label_path):\n",
    "        image_path = os.path.join(label_path, image)\n",
    "\n",
    "        # Add class and path to restrictive lists\n",
    "        classes.append(label)\n",
    "        class_paths.append(image_path)\n",
    "\n",
    "  # Create a DataFrame with the collected data\n",
    "  df = pd.DataFrame({\n",
    "      'Class Path': class_paths,\n",
    "      'Class': classes\n",
    "  })\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = get_class_paths(\"Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = get_class_paths(\"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "ax = sns.countplot(data=tr_df, x=tr_df[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "ax = sns.countplot(data=ts_df, x=ts_df[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df, ts_df = train_test_split(ts_df, train_size=0.5, stratify=ts_df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "img_size = (299, 299)\n",
    "\n",
    "image_generator = ImageDataGenerator(rescale=1/255, brightness_range=(0.8, 1.2))\n",
    "\n",
    "ts_gen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen = image_generator.flow_from_dataframe(tr_df, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n",
    "\n",
    "valid_gen = image_generator.flow_from_dataframe(valid_df, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n",
    "\n",
    "ts_gen = ts_gen.flow_from_dataframe(ts_df, x_col='Class Path', y_col='Class', batch_size=16, target_size=img_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i in range (16):\n",
    "  plt.subplot(4, 4, i+1)\n",
    "  batch = next(tr_gen)\n",
    "  image = batch[0][0]\n",
    "  label = batch[1][0]\n",
    "  plt.imshow(image)\n",
    "\n",
    "  # Get the class index\n",
    "  class_index = np.argmax(label)\n",
    "\n",
    "  # Get the list of class names and class indeies\n",
    "  class_names = list(tr_gen.class_indices.keys())\n",
    "  class_indices = list(tr_gen.class_indices.values())\n",
    "\n",
    "  # Find the index of the class_index in the list of indices\n",
    "  index_position = class_indices.index(class_index)\n",
    "\n",
    "  # Get the class name using the index position\n",
    "  class_name = class_names[index_position]\n",
    "\n",
    "  plt.title(f\"Class: {class_name}\")\n",
    "  plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (299, 299, 3)\n",
    "\n",
    "base_model = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\", input_shape= img_shape, pooling='max')\n",
    "\n",
    "model = Sequential([base_model, Flatten(), Dropout(rate= 0.3), Dense(128, activation= 'relu'), Dropout(rate= 0.25), Dense(4, activation= 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy', Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(tr_gen, epochs=5, validation_data=valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Get training and validation metrics from history\n",
    "metrics = ['accuracy', 'precision', 'loss', 'recall']  \n",
    "tr_metrics = {m: hist.history[m] for m in metrics}\n",
    "val_metrics = {m: hist.history[f'val_{m}'] for m in metrics}\n",
    "\n",
    "# Find best epochs and values\n",
    "best_epochs = {}\n",
    "best_values = {}\n",
    "for m in metrics:\n",
    "    if m == 'loss':\n",
    "        idx = np.argmin(val_metrics[m])\n",
    "    else:\n",
    "        idx = np.argmax(val_metrics[m])\n",
    "    best_epochs[m] = idx + 1\n",
    "    best_values[m] = val_metrics[m][idx]\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    epochs = range(1, len(tr_metrics[metric]) + 1)\n",
    "    \n",
    "    plt.plot(epochs, tr_metrics[metric], 'r', label=f'Training {metric}')\n",
    "    plt.plot(epochs, val_metrics[metric], 'g', label=f'Validation {metric}')\n",
    "    plt.scatter(best_epochs[metric], best_values[metric], s=150, c='blue', \n",
    "                label=f'Best epoch = {best_epochs[metric]}')\n",
    "    \n",
    "    plt.title(f'Training and Validation {metric.title()}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric.title())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.suptitle('Model Training Metrics Over Epochs', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(tr_gen, verbose=1)\n",
    "valid_score = model.evaluate(valid_gen, verbose=1)\n",
    "test_score = model.evaluate(ts_gen, verbose=1)\n",
    "\n",
    "print(f\"Training Accuracy: {train_score[1]*100:.2f}%\")\n",
    "print(f\"Validation Loss: {valid_score[0]:.4f}\")\n",
    "print(f\"\\n\\nValidation Accuracy: {valid_score[1]*100:.2f}%\")\n",
    "print(f\"Validation Loss: {valid_score[0]:.4f}\")\n",
    "print(f\"\\n\\nTest Accuracy: {test_score[1]*100:.2f}%\")\n",
    "print(f\"Testing Loss: {test_score[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(ts_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "class_dict = {\n",
    "  0: 'glioma',\n",
    "  1: 'meningioma',\n",
    "  2: 'no_tumor',\n",
    "  3: 'pituitary'\n",
    "}\n",
    "\n",
    "# Then create a display the confusion matrix\n",
    "cm = confusion_matrix(ts_gen.classes, y_pred)\n",
    "labels = list(class_dict.keys())\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict(img_path: str) -> None:\n",
    "  # Get class labels\n",
    "  labels = list(class_dict.keys())\n",
    "\n",
    "  # Load a process image\n",
    "  img = Image.open(img_path)\n",
    "  resized_image = img.resize((299, 299))\n",
    "  img_array = np.asarray(resized_image)\n",
    "  img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "  # Get model predictions\n",
    "  predictions = model.predict(img_array)\n",
    "  probabilities = list(predictions[0])\n",
    "\n",
    "  # Get Predicted class\n",
    "  predicted_class_idx = np.argmax(probabilities)\n",
    "  predicted_class = class_dict[predicted_class_idx]\n",
    "\n",
    "  # Plot original image\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.imshow(resized_image)\n",
    "  plt.title(f\"Input MRI Image\\nPredicted: {predicted_class}\")\n",
    "\n",
    "  # Plot prediction probabilities\n",
    "  plt.subplot(2, 1, 2)\n",
    "  bars = plt.barh(labels, probabilities)\n",
    "  plt.xlabel(\"Probability\", fontsize=15)\n",
    "  plt.title(\"Class Probabilities\")\n",
    "\n",
    "  # Add probability labels to bars\n",
    "  ax = plt.gca()\n",
    "  ax.bar_label(bars, fmt='%.2f')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  print(f\"\\nPredicted tumor type: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Testing/meningioma/Te-me_0011.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Testing/meningioma/Te-me_0015.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Testing/glioma/Te-gl_0010.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"xception_model.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "img_size = (224, 224)\n",
    "\n",
    "\n",
    "image_generator = ImageDataGenerator(rescale=1/255, brightness_range=(0.8, 1.2))\n",
    "\n",
    "ts_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "tr_gen = image_generator.flow_from_dataframe(tr_df, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n",
    "\n",
    "valid_gen = image_generator.flow_from_dataframe(valid_df, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n",
    "\n",
    "ts_gen = ts_gen.flow_from_dataframe(ts_df, x_col='Class Path', y_col='Class', batch_size=16, target_size=img_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "\n",
    "cnm_model = Sequential()\n",
    "\n",
    "# Convolution Layers\n",
    "cnm_model.add(Conv2D(512, (3, 3), padding= 'same', input_shape=(224, 224, 3), activation= 'relu'))\n",
    "cnm_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnm_model.add(Conv2D(256, (3, 3), padding= 'same', activation= 'relu'))\n",
    "cnm_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnm_model.add(Dropout(0.25))\n",
    "\n",
    "cnm_model.add(Conv2D(128, (3, 3), padding= 'same', activation= 'relu'))\n",
    "cnm_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnm_model.add(Dropout(0.25))\n",
    "\n",
    "cnm_model.add(Conv2D(64, (3, 3), padding= 'same', activation= 'relu'))\n",
    "cnm_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output for fully connected layers\n",
    "cnm_model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "cnm_model.add(Dense(256, activation= 'relu', kernel_regularizer= regularizers.l2(0.01)))\n",
    "cnm_model.add(Dropout(0.35))\n",
    "\n",
    "# Output layer with 4 neurons for the 4 classes\n",
    "cnm_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "cnm_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Display the model summary\n",
    "cnm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnm_model.fit(tr_gen, epochs=5, validation_data=valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Get training and validation metrics from history\n",
    "metrics = ['accuracy', 'precision_2', 'loss', 'recall_2']  \n",
    "tr_metrics = {m: history.history[m] for m in metrics}\n",
    "val_metrics = {m: history.history[f'val_{m}'] for m in metrics}\n",
    "\n",
    "# Find best epochs and values\n",
    "best_epochs = {}\n",
    "best_values = {}\n",
    "for m in metrics:\n",
    "    if m == 'loss':\n",
    "        idx = np.argmin(val_metrics[m])\n",
    "    else:\n",
    "        idx = np.argmax(val_metrics[m])\n",
    "    best_epochs[m] = idx + 1\n",
    "    best_values[m] = val_metrics[m][idx]\n",
    "\n",
    "# Plot metrics\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "for i, metric in enumerate(metrics, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    epochs = range(1, len(tr_metrics[metric]) + 1)\n",
    "    \n",
    "    plt.plot(epochs, tr_metrics[metric], 'r', label=f'Training {metric}')\n",
    "    plt.plot(epochs, val_metrics[metric], 'g', label=f'Validation {metric}')\n",
    "    plt.scatter(best_epochs[metric], best_values[metric], s=150, c='blue', \n",
    "                label=f'Best epoch = {best_epochs[metric]}')\n",
    "    \n",
    "    plt.title(f'Training and Validation {metric.title()}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric.title())\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.suptitle('Model Training Metrics Over Epochs', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = cnm_model.evaluate(tr_gen, verbose=1)\n",
    "valid_score = cnm_model.evaluate(valid_gen, verbose=1)\n",
    "test_score = cnm_model.evaluate(ts_gen, verbose=1)\n",
    "\n",
    "print(f\"Training Accuracy: {train_score[1]*100:.2f}%\")\n",
    "print(f\"Validation Loss: {valid_score[0]:.4f}\")\n",
    "print(f\"\\n\\nValidation Accuracy: {valid_score[1]*100:.2f}%\")\n",
    "print(f\"Validation Loss: {valid_score[0]:.4f}\")\n",
    "print(f\"\\n\\nTest Accuracy: {test_score[1]*100:.2f}%\")\n",
    "print(f\"Testing Loss: {test_score[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnm_model.predict(ts_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "class_dict = {\n",
    "  0: 'glioma',\n",
    "  1: 'meningioma',\n",
    "  2: 'no_tumor',\n",
    "  3: 'pituitary'\n",
    "}\n",
    "\n",
    "# Then create a display the confusion matrix\n",
    "cm = confusion_matrix(ts_gen.classes, y_pred)\n",
    "labels = list(class_dict.keys())\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr = classification_report(ts_gen.classes, y_pred)\n",
    "print(clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm_model.save_weights(\"cnm_model.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (1.40.0)\n",
      "Requirement already satisfied: pyngrok in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (7.2.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (5.4.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (18.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: jinja2 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.13.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit pyngrok python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from threading import Thread\n",
    "from pyngrok import ngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "ngrok_token = os.getenv('NGROK_AUTH_TOKEN')\n",
    "ngrok.set_auth_token(ngrok_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_streamlit():\n",
    "  os.system(\"streamlit run main.py --server.port 8501\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import PIL.Image\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "output_dir = \"saliency_maps\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def load_model(model_path):\n",
    "    try:\n",
    "        # Load the entire model\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        return model\n",
    "    except:\n",
    "        # If loading fails, recreate the model architecture and load weights\n",
    "        model = Sequential([\n",
    "            Conv2D(512, (3, 3), padding='same', input_shape=(224, 224, 3), activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Dropout(0.25),\n",
    "            Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Dropout(0.25),\n",
    "            Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "            Dropout(0.35),\n",
    "            Dense(4, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            Adamax(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', Precision(), Recall()]\n",
    "        )\n",
    "        \n",
    "        # Load weights\n",
    "        model.load_weights(model_path)\n",
    "        return model\n",
    "\n",
    "def generate_explanation(model, model_prediction, confidence):\n",
    "\n",
    "  prompt = f\"\"\" \n",
    "  You are an expert neurologist analyzing a brain tumor MRI scan with an overlaid saliency map. This map highlights in light cyan the areas the deep learning model focused on to classify the brain tumor. The model has classified the tumor as '{model_prediction}' with a confidence level of {confidence*100}%.\n",
    "\n",
    "  In your analysis:\n",
    "  - Identify the specific brain regions in the MRI that the model is concentrating on, based on the light cyan areas in the saliency map, and describe any significant anatomical landmarks or structures that fall within these highlighted regions.\n",
    "  - Discuss plausible reasons why the model focused on these specific regions for the given classification, considering the typical tumor characteristics and growth patterns associated with glioma, meningioma, pituitary tumors, or no tumor.\n",
    "  - Offer an insight into how the highlighted areas might correlate with the model's predicted tumor type.\n",
    "\n",
    "  Do not mention the model at all in your explanation.\n",
    "  Do not mention the work 'model' in your explanation.\n",
    "\n",
    "  Keep your explanation concise and limited to 4 sentences. Ensure clarity and precision in your analysis by verifying each step logically.\n",
    "    \"\"\"\n",
    "\n",
    "  # img = PIL.Image.open(img_path)\n",
    "  image_path = os.path.join(output_dir, uploaded_file.name)\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        # model=\"gpt-4-vision-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "  return response.choices[0].message.content\n",
    "\n",
    "def generate_saliency_map(model, img_array, class_index, img_size):\n",
    "  with tf.GradientTape() as tape:\n",
    "    img_tensor = tf.convert_to_tensor(img_array)\n",
    "    tape.watch(img_tensor)\n",
    "    predictions = model(img_tensor)\n",
    "    target_class = predictions[:, class_index]\n",
    "\n",
    "    gradients = tape.gradient(target_class, img_tensor)\n",
    "    gradients = tf.math.abs(gradients)\n",
    "    gradients = tf.reduce_max(gradients, axis=-1)\n",
    "    gradients = gradients.numpy().squeeze()\n",
    "\n",
    "    # Resize gradients to match the original image size\n",
    "    gradients = cv2.resize(gradients, img_size)\n",
    "\n",
    "    # Create a circular mask for the brain area\n",
    "    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)\n",
    "    radius = min(center[0], center[1]) - 10\n",
    "    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]\n",
    "    mask = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= radius ** 2\n",
    "\n",
    "    # Apply the mask to gradients\n",
    "    gradients = gradients * mask\n",
    "\n",
    "    # Normalize only the brain area\n",
    "    brain_gradients = gradients[mask]\n",
    "    if brain_gradients.max() > brain_gradients.min():\n",
    "      brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())\n",
    "    gradients[mask] = brain_gradients\n",
    "\n",
    "    # Apply a higher threshold\n",
    "    threshold = np.percentile(gradients[mask], 80)\n",
    "    gradients[gradients < threshold] = 0\n",
    "\n",
    "    # Apply more aggressive smoothing\n",
    "    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)\n",
    "\n",
    "    # Create a heatmap overlay with enhanced contrast\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize heatmap to match the original image size\n",
    "    heatmap = cv2.resize(heatmap, img_size)\n",
    "\n",
    "    # Superimpose the heatmap on original image with increased opacity\n",
    "    original_image = image.img_to_array(img)\n",
    "    superimposed_img = heatmap * 0.7 + original_image * 0.3\n",
    "    superimposed_img = superimposed_img.astype(np.uint8)\n",
    "\n",
    "    img_path = os.path.join(output_dir, uploaded_file.name)\n",
    "    with open(img_path, 'wb') as f:\n",
    "      f.write(uploaded_file.getbuffer())\n",
    "\n",
    "    saliency_map_path = f\"saliency_maps/{uploaded_file.name}\"\n",
    "\n",
    "    # Save the saliency map\n",
    "    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    return superimposed_img\n",
    "\n",
    "def load_xception_model(model_path):\n",
    "  img_shape = (299, 299, 3)\n",
    "  base_model = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\", input_shape= img_shape, pooling='max')\n",
    "\n",
    "  model = Sequential([base_model, Flatten(), Dropout(rate= 0.3), Dense(128, activation= 'relu'), Dropout(rate= 0.25), Dense(4, activation='softmax')])\n",
    "\n",
    "  model.build((None,) + img_shape)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(Adamax(learning_rate= 0.001), loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "  model.load_weights(model_path)\n",
    "\n",
    "  return model\n",
    "\n",
    "st.title(\"Brain Tumor Classification\")\n",
    "\n",
    "# Upload Image\n",
    "st.write(\"Upload an image of a brain MRI scan to classify the type of tumor.\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "\n",
    "  selected_model = st.radio(\n",
    "    \"Select Model\",\n",
    "    (\"Transfer Learning - Xception\", \"Custom CNN\")  \n",
    "  )\n",
    "\n",
    "  if selected_model == \"Transfer Learning - Xception\":\n",
    "    model = load_xception_model(\"xception_model.weights.h5\")\n",
    "    img_size = (299, 299)\n",
    "  else:\n",
    "    model = load_model(\"cnm_model.weights.h5\")\n",
    "    img_size = (224, 224)\n",
    "\n",
    "  labels = ['Glioma', 'Meningioma', 'No_tumor', 'Pituitary']\n",
    "  img = image.load_img(uploaded_file, target_size=img_size)\n",
    "  img_array = image.img_to_array(img)\n",
    "  img_array = np.expand_dims(img_array, axis=0)\n",
    "  img_array = img_array / 255.0\n",
    "\n",
    "  predictions = model.predict(img_array)\n",
    "\n",
    "  # Get the class with the highest probability\n",
    "  class_index = np.argmax(predictions[0])\n",
    "  result = labels[class_index]\n",
    "\n",
    "  st.write(f\"Predicted Class: {result}\")\n",
    "  st.write(\"Predictions:\")\n",
    "  for label, prob in zip(labels, predictions[0]):\n",
    "    st.write(f\"{label}: {prob:.4f}\")\n",
    "\n",
    "  # Generate saliency map\n",
    "  saliency_map = generate_saliency_map(model, img_array, class_index, img_size)\n",
    "\n",
    "  col1, col2 = st.columns(2)\n",
    "  with col1:\n",
    "    st.image(uploaded_file, caption=\"Uploaded Image\", use_container_width=True)\n",
    "  with col2:\n",
    "    st.image(saliency_map, caption=\"Saliency Map\", use_container_width=True)\n",
    "\n",
    "  st.write(\"## Classification Results:\")\n",
    "\n",
    "  result_container = st.container()\n",
    "  result_container = st.container()\n",
    "  result_container.markdown(\n",
    "    f\"\"\" \n",
    "    <div style=\"background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px\">\n",
    "      <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "        <div style=\"flex: 1; text-align: center;\">\n",
    "          <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Prediction</h3>\n",
    "          <p style=\"font-size: 36px; font-weight: 800; color: #FF0000; margin: 0;\">\n",
    "            {result}\n",
    "          </p>\n",
    "        </div>\n",
    "        <div style=\"width: 2px; height: 80px; background-color: #ffffff; margin: 0 20px;\"></div>\n",
    "        <div style=\"flex: 1; text-align: center;\">\n",
    "          <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Confidence</h3>\n",
    "          <p style=\"font-size: 36px; font-weight: 800; color: #2196F3; margin: 0\">\n",
    "            {predictions[0][class_index]:.4%}\n",
    "          </p>\n",
    "        </div>\n",
    "        \n",
    "      </div>\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html= True\n",
    "  )\n",
    "\n",
    "  # Prepare data for Plotly chart\n",
    "  probabilities = predictions[0]\n",
    "  sorted_indices = np.argsort(probabilities)[::-1]\n",
    "  sorted_labels = [labels[i] for i in sorted_indices]\n",
    "  sorted_probabilities = probabilities[sorted_indices]\n",
    "\n",
    "  # Create a Plotly chart\n",
    "  fig = go.Figure(go.Bar(\n",
    "  x=sorted_probabilities,\n",
    "  y=sorted_labels,\n",
    "  orientation= 'h',\n",
    "  marker_color=['red' if label == result else 'blue' for label in sorted_labels]\n",
    "  ))\n",
    "\n",
    "  # Customize the chart layout\n",
    "  fig.update_layout(\n",
    "  title='Probabilities for each class',\n",
    "  xaxis_title='Probability',\n",
    "  yaxis_title='Class',\n",
    "  height= 400,\n",
    "  width=600,\n",
    "  yaxis=dict(autorange= 'reversed')\n",
    "  )\n",
    "\n",
    "  # Add value labels to the bars\n",
    "  for i, prob in enumerate(sorted_probabilities):\n",
    "    fig.add_annotation(\n",
    "      x=prob,\n",
    "      y=i,\n",
    "      text=f'{prob:.4f}',\n",
    "      showarrow= False,\n",
    "      xanchor='left',\n",
    "      xshift=5\n",
    "    )\n",
    "\n",
    "  # Display the Plotly chart\n",
    "  st.plotly_chart(fig)\n",
    "\n",
    "  saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n",
    "\n",
    "  explanation = generate_explanation(saliency_map_path, result, predictions[0][class_index])\n",
    "\n",
    "  st.write(\"## Explanation:\")\n",
    "  st.write(explanation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://10.189.0.83:8501\n",
      "\n",
      "  For better performance, install the Watchdog module:\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 17:40:11.331705: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-11-11 17:40:11.331744: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-11-11 17:40:11.331748: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-11-11 17:40:11.332064: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-11 17:40:11.332077: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/paulc1/miniforge3/envs/tumor-classification/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 2 variables whereas the saved optimizer has 318 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2024-11-11 17:40:13.220706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "thread = Thread(target=run_streamlit)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ngrok' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m public_url \u001b[38;5;241m=\u001b[39m \u001b[43mngrok\u001b[49m\u001b[38;5;241m.\u001b[39mconnect(addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8501\u001b[39m\u001b[38;5;124m\"\u001b[39m, proto\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m, bind_tls\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m tunnels \u001b[38;5;241m=\u001b[39m ngrok\u001b[38;5;241m.\u001b[39mget_tunnels()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tunnel \u001b[38;5;129;01min\u001b[39;00m tunnels:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ngrok' is not defined"
     ]
    }
   ],
   "source": [
    "public_url = ngrok.connect(addr=\"8501\", proto=\"http\", bind_tls=True)\n",
    "\n",
    "tunnels = ngrok.get_tunnels()\n",
    "for tunnel in tunnels:\n",
    "  print(f\"Closing tunnel: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
    "  ngrok.disconnect(tunnel.public_url)\n",
    "print(\"\\n\")\n",
    "\n",
    "public_url = ngrok.connect(addr=\"8501\", proto=\"http\", bind_tls=True)\n",
    "\n",
    "print(\"Public URL:\", public_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tumor-classification)",
   "language": "python",
   "name": "tumor-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
